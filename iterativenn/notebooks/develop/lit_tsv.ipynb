{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e96298-e263-4148-81fd-efa4a2285e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=100, output_size=12):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "\n",
    "    \n",
    "class TimeStepVaryingLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    input_seq: sequence tensor\n",
    "    target_seq: sequence tensor\n",
    "    time_step_dict:\n",
    "    {'mse': [start_time_step: int, end_time_step: int, weight: float], \n",
    "     'l1_loss': [start_time_step: int, end_time_step: int, weight: float]}\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "        self.cross_entropy = nn.CrossEntropyLoss()\n",
    "        self.l1_loss = nn.L1Loss()\n",
    "        self.t_loss = []\n",
    "        \n",
    "    def forward(self, input_seq, target_seq, time_step_dict):\n",
    "        for loss_key, values in time_step_dict.items():\n",
    "            a = values[0]\n",
    "            b = values[1]\n",
    "            with torch.no_grad():\n",
    "                w = torch.tensor(values[2])\n",
    "            if loss_key ==\"mse\":    \n",
    "                self.t_loss.append(w*self.loss_mse(input_seq[a:b], target_seq[a:b]))\n",
    "            elif loss_key ==\"cross-entropy\":\n",
    "                self.t_loss.append(w*self.cross_entropy(input_seq[a:b], target_seq[a:b]))\n",
    "            elif loss_key ==\"l1-loss\":\n",
    "                self.t_loss.append(w*self.l1_loss(input_seq[a:b], target_seq[a:b]))\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        return sum(self.t_loss)\n",
    "        \n",
    "        \n",
    "class LitWrappedLSTM(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    This implements a module which trains a MaskedLinear module.     \n",
    "    Should be very simple.  Just give it a MaskedLinear module, and it will train it.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size=784, hidden_size=100, output_size=10):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.model = LSTM()\n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=10)\n",
    " \n",
    "    def forward(self, input_seq):\n",
    "        return self.model(input_seq)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "    # when you call this, you will likely want to turn off\n",
    "    # the automatic batching since the default collate_fn\n",
    "    # raises errors with variable length image sequences    \n",
    "    # https://pytorch.org/docs/stable/data.html\n",
    "    def training_step(self, train_item, batch_idx):\n",
    "        x_sequence, y_sequence = train_item#['x'], train_item['y']\n",
    "        self.model.hidden_cell = (torch.zeros(1, 1, self.model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, self.model.hidden_layer_size))\n",
    "        y_pred = self.model(x_sequence)\n",
    "        tsv_loss = TimeStepVaryingLoss()\n",
    "        sequence_loss  = tsv_loss(y_pred, y_sequence, {'mse': [0, 6, 1],'l1-loss': [6, 12, 1]})\n",
    "        self.log('train_loss', sequence_loss, on_epoch=True, batch_size=1) # TODO: check the sequence_loss loss betwwen lstm and mlp.\n",
    "        self.log('train_acc_step', self.accuracy)\n",
    "        return sequence_loss\n",
    "\n",
    "\n",
    "    # when you call this, you will likely want to turn off\n",
    "    # the automatic batching since the default collate_fn\n",
    "    # raises errors with variable length image sequences    \n",
    "    # https://pytorch.org/docs/stable/data.html\n",
    "    def validation_step(self, val_item, batch_idx):\n",
    "        x_sequence, y_sequence = val_item\n",
    "        self.model.hidden_cell = (torch.zeros(1, 1, self.model.hidden_layer_size),\n",
    "                            torch.zeros(1, 1, self.model.hidden_layer_size))\n",
    "        y_pred = self.model(x_sequence)\n",
    "        tsv_loss = TimeStepVaryingLoss()\n",
    "        sequence_loss  = tsv_loss(y_pred, y_sequence, {'mse': [0, 6, 1],'l1-loss': [6, 12, 1]})\n",
    "        self.log('val_loss', sequence_loss, on_epoch=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520d9a71-533b-404c-a065-998a089d57bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy flights price data\n",
    "all_data = \"112. 118. 132. 129. 121. 135. 148. 148. 136. 119. 104. 118. 115. 126. 141. 135. 125. 149. 170. 170. 158. 133. 114. 140. 145. 150. 178. 163. 172. 178. 199. 199. 184. 162. 146. 166. 171. 180. 193. 181. 183. 218. 230. 242. 209. 191. 172. 194. 196. 196. 236. 235. 229. 243. 264. 272. 237. 211. 180. 201. 204. 188. 235. 227. 234. 264. 302. 293. 259. 229. 203. 229. 242. 233. 267. 269. 270. 315. 364. 347. 312. 274. 237. 278. 284. 277. 317. 313. 318. 374. 413. 405. 355. 306. 271. 306. 315. 301. 356. 348. 355. 422. 465. 467. 404. 347. 305. 336. 340. 318. 362. 348. 363. 435. 491. 505. 404. 359. 310. 337. 360. 342. 406. 396. 420. 472. 548. 559. 463. 407. 362. 405. 417. 391. 419. 461. 472. 535. 622. 606. 508. 461. 390. 432.\".split(\" \")\n",
    "all_data = [float(i) for i in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b094464-283b-4a27-a624-657306e2a40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_size = 12\n",
    "\n",
    "train_data = all_data[:-test_data_size]\n",
    "test_data = all_data[-test_data_size:]\n",
    "\n",
    "train_window = 12\n",
    "train_data = torch.FloatTensor(train_data).view(-1)\n",
    "\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = input_data[i:i+tw]\n",
    "        train_label = input_data[i+tw:i+tw+tw]\n",
    "        if len(train_label)==12:\n",
    "            inout_seq.append((train_seq ,train_label))\n",
    "    return inout_seq\n",
    "\n",
    "train_inout_seq = create_inout_sequences(train_data, train_window)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbce7c1c-8a90-43dd-911b-176a44496e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([112., 118., 132., 129., 121., 135., 148., 148., 136., 119., 104., 118.]),\n",
       "  tensor([115., 126., 141., 135., 125., 149., 170., 170., 158., 133., 114., 140.])),\n",
       " (tensor([118., 132., 129., 121., 135., 148., 148., 136., 119., 104., 118., 115.]),\n",
       "  tensor([126., 141., 135., 125., 149., 170., 170., 158., 133., 114., 140., 145.])),\n",
       " (tensor([132., 129., 121., 135., 148., 148., 136., 119., 104., 118., 115., 126.]),\n",
       "  tensor([141., 135., 125., 149., 170., 170., 158., 133., 114., 140., 145., 150.])),\n",
       " (tensor([129., 121., 135., 148., 148., 136., 119., 104., 118., 115., 126., 141.]),\n",
       "  tensor([135., 125., 149., 170., 170., 158., 133., 114., 140., 145., 150., 178.])),\n",
       " (tensor([121., 135., 148., 148., 136., 119., 104., 118., 115., 126., 141., 135.]),\n",
       "  tensor([125., 149., 170., 170., 158., 133., 114., 140., 145., 150., 178., 163.]))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b2bf74-e547-4ee4-9f85-619e8392c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_train_inout_seq = torch.utils.data.DataLoader(train_inout_seq, num_workers=1, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d354cff-823d-4e73-87b3-a348ee26b54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=None,\n",
    "                         enable_progress_bar=False,\n",
    "                         precision=16,\n",
    "                         max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e773dd6e-8018-47cd-857e-639206eb28e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitWrappedLSTM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c961359-7b18-422b-b45a-25624f314aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | LSTM               | 42.4 K\n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "42.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "42.4 K    Total params\n",
      "0.170     Total estimated model params size (MB)\n",
      "/home/rcpaffenroth/projects/iterativenn/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/rcpaffenroth/projects/iterativenn/venv/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(lit_model, torch_train_inout_seq, torch_train_inout_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37bdcad-d321-4b51-b026-aeedfb941252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "91c69d281b806a3add6b161e23d9089dcb392788fdbe6cdd17c006940cab5b65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
