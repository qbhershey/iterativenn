{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3a8589c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from iterativenn.utils.data_factory import DataFactory\n",
    "from iterativenn.utils.DataModules import LMDataModule\n",
    "from iterativenn.nn_modules.Sequential2D import Sequential2D\n",
    "from iterativenn.lit_modules import IteratedModelBatch\n",
    "from torch.utils.data import DataLoader\n",
    "import logging\n",
    "import warnings\n",
    "import torchtext\n",
    "import datasets\n",
    "from transformers import (\n",
    "    AutoModelForMaskedLM,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    ")\n",
    "from transformers.optimization import AdamW\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.utils.checkpoint\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b11f9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_max_epochs = 1\n",
    "global_optimizer = 'SGD'\n",
    "model_name_or_path=\"bert-base-cased\"\n",
    "config = AutoConfig.from_pretrained(\n",
    "            model_name_or_path, return_dict=True)\n",
    "\n",
    "output_len = config.vocab_size\n",
    "\n",
    "cfg = {\n",
    "    \"sequential2D\": {\n",
    "        \"in_features_list\": [768, 10, output_len], \n",
    "        \"out_features_list\": [768, 10, output_len], \n",
    "\n",
    "\n",
    "        \"block_types\": [\n",
    "            [None, 'Linear', None],\n",
    "            [None, None, 'Linear'],\n",
    "            [None, None, None],\n",
    "        ],\n",
    "        \"block_kwargs\": [\n",
    "            [None, None, None],\n",
    "            [None, None, None],\n",
    "            [None, None, None],\n",
    "        ]\n",
    "    },\n",
    "    \"callbacks\": {\n",
    "        \"loss\": {\n",
    "            \"func\": \"CrossEntropyLoss\",\n",
    "            \"idx_list\" : range(768+10, 768+10+output_len),\n",
    "            \"sequence_position\": 'all',\n",
    "        },\n",
    "        \"initialization\": {\n",
    "            \"func\": \"zeros\",\n",
    "            \"size\":768+10+output_len,\n",
    "            \"seq_len\": 3,\n",
    "            \"batch_size\": 4,\n",
    "        },\n",
    "        \"data\": {\n",
    "            \"func\": \"insert\",\n",
    "            \"idx_list\": range(768),\n",
    "            \"flatten_input\": False,            \n",
    "        },\n",
    "        \"output\": {\n",
    "            \"func\": \"max\",\n",
    "            \"idx_list\" : range(768+10, 768+10+output_len)\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aefad2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No optimization routine provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/Users/hpathak/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.022897005081176758,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342967d4c07b4e86968a932b5e9f1c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/hpathak/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-b8fb876458051540.arrow\n",
      "Loading cached processed dataset at /Users/hpathak/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-6e4784073618cb72.arrow\n",
      "Loading cached processed dataset at /Users/hpathak/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-8aa87176c76c40ea.arrow\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010191679000854492,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 4358,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009407997131347656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 36718,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/36718 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009402990341186523,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 50,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 3760,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:613: UserWarning: Checkpoint directory outputs/nlp-demo/main/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "\n",
      "  | Name  | Type         | Params\n",
      "---------------------------------------\n",
      "0 | model | Sequential2D | 326 K \n",
      "---------------------------------------\n",
      "326 K     Trainable params\n",
      "0         Non-trainable params\n",
      "326 K     Total params\n",
      "1.307     Total estimated model params size (MB)\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: nan\n",
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/hpathak/opt/anaconda3/envs/res/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "data_module = LMDataModule(\n",
    "        model_name_or_path='distilbert-base-cased',\n",
    "        line_by_line=False,\n",
    "        pad_to_max_length=False,\n",
    "        preprocessing_num_workers=1,\n",
    "        overwrite_cache=False,\n",
    "        max_seq_length=3,\n",
    "        mlm_probability=0.15,\n",
    "        train_batch_size=4,\n",
    "        val_batch_size=4,\n",
    "        dataloader_num_workers=8,\n",
    "    )\n",
    "\n",
    "\n",
    "logger = TensorBoardLogger(\"outputs\", name=\"nlp-demo\", version='main')\n",
    "\n",
    "\n",
    "sequential2D = Sequential2D.from_config(cfg[\"sequential2D\"])\n",
    "callbacks = IteratedModelBatch.ConfigCallbacks(cfg[\"callbacks\"])\n",
    "model = IteratedModelBatch.IteratedModelNLP(sequential2D, callbacks, optimizer=global_optimizer)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "trainer = Trainer(\n",
    "        accelerator='auto',\n",
    "        devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "        max_epochs=global_max_epochs,\n",
    "        log_every_n_steps=1,\n",
    "        enable_progress_bar=False,\n",
    "        logger=logger)\n",
    "\n",
    "trainer.fit(model, data_module)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d3b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d2f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf255a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
